---
title: "Factorización QR"
format: html
---
El método de Gram schmid consiste en tomar un conjunto de vectores linealmete independientes y construir un conjunto de vectores ortogonales a partir de ellos. Para ello se toma el primer vector y se normaliza, luego se toma el segundo vector y se le resta la proyección de este sobre el primero, luego se normaliza y se repite el proceso con el tercer vector y así sucesivamente. El resultado es un conjunto de vectores ortogonales que son linealmente independientes.


El método de Gram schmid es un método iterativo que se puede expresar de la siguiente manera:
sea $A_1, A_2, \dots, A_n$ un conjunto de vectores linealmente independientes, entonces se define el conjunto de vectores ortogonales $u_1, u_2, \dots, u_n$ de la siguiente manera:
$$u_1 = \frac{A_1}{\|A_1\|},$$
$$\overline{u}_2 = A_2 - \langle u_1, A_2 \rangle u_1,$$
$$u_2=\|\overline{u}_2 \|,$$
$$\overline{u}_3 = A_3 -\sum_{j=1}^2 \langle u_j, A_3 \rangle u_j, $$
$$u_3=\|\overline{u}_3 \|,$$
$$\vdots$$
$$\overline{u}_n = A_n  -\sum_{j=1}^{n-1} \langle u_j, A_n \rangle u_j, $$    
$$u_n=\|\overline{u}_n \|.$$

Ahora si escribimos una matriz $A$ de $m\times n$, con $m>n$ formada por los vectores $A_1, A_2, \dots, A_n$ como columnas. Note que $rank(A)=n vamos a reproducir el proceso anterior, pero ahora en forma matricial. 

$$y_1=A_1, \text{ y } q_1=\frac{y_1}{\|y_1\|},$$
ahora para encontrar el segundo vector $y_2$ se tiene que:
$$y_2=A_2-q_1(q_1^TA_2), \text{ y } q_1=\frac{y_1}{\|y_1\|},$$

y así sucesivamente hasta encontrar $y_n$ y $q_n$.
$$y_n=A_n-\sum_{j=1}^{n-1} q_j(q_j^TA_n), \text{ y } q_n=\frac{y_n}{\|y_n\|}.$$


Note que de esta forma podemos escribir $A$ como:

$$A_1=r_{11}q_1,$$
$$A_2=r_{21}q_1+r_{22}q_2,$$
y
$$ A_n=r_{n1}q_1+r_{n2}q_2+r_{n3}q_3+\dots+r_{nn}q_n.$$

De esta forma podemos escribir $A$ como el producto de dos matrices $Q$ y $R$ donde $Q$ es una matriz ortogonal y $R$ es una matriz triangular superior.

$$A=[A_1|A_2|...|A_n]=[q_1|q_2|...|q_n]\begin{bmatrix}
r_{11} & r_{12} & ...&r_{1n}\\
& r_{12} & ...&r_{1n}\\
&  &\ddots&\vdots\\
& & ...&r_{nn}\\
\end{bmatrix}$$

Este procedimeinto se llama la factorización QR de $A$.


![Gram-Schmidt](figures/QR1.png)


```{python}
import numpy as np

np.set_printoptions(suppress=True, precision=4)  # precision work

def cgs(A):
    m, n = A.shape
    Q = np.zeros([m,n], dtype=np.float64)
    R = np.zeros([n,n], dtype=np.float64)
    for j in range(n):
        v = A[:,j]
        for i in range(j):
            R[i,j] = np.dot(Q[:,i], A[:,j])
            v = v - (R[i,j] * Q[:,i])
        R[j,j] = np.linalg.norm(v)
        Q[:, j] = v / R[j,j]
    return Q, R
```
ahora vamos a probar el método con una matriz aleatoria de $m\times n$ con $m>n$.

```{python}
## creation of example matrix
n = 6
A = np.random.rand(n,n)

Q, R = cgs(A)

## comprobation 
## Con este c[odigo comprobamos si Q*R es igual a A

np.allclose(A, Q @ R)
```

Método de Gram-Schmidt modificado

El método de Gram-Schmidt modificado es una variación del método de Gram-Schmidt. En este método se toma el primer vector y se normaliza, luego se toma el segundo vector y se le resta la proyección de este sobre el primero, luego se normaliza y se repite el proceso con el tercer vector y así sucesivamente. El resultado es un conjunto de vectores ortogonales que son linealmente independientes. El método de Gram-Schmidt modificado es un método iterativo que se puede expresar de la siguiente manera:

![Gram-Schmidt](figures/QR2.png)

```{python}
def mgs(A):
    V = A.copy()
    m, n = A.shape
    Q = np.zeros([m,n], dtype=np.float64)
    R = np.zeros([n,n], dtype=np.float64)
    for i in range(n):
        R[i,i] = np.linalg.norm(V[:,i])
        Q[:,i] = V[:,i] / R[i,i]
        for j in range(i, n):
            R[i,j] = np.dot(Q[:,i],V[:,j])
            V[:,j] = V[:,j] - R[i,j]*Q[:,i]
    return Q, R
```

# Nota
Si $A_{n\times n}$, donde cada una de sus columnas son linealmente idependientes  entonces las columnas  de  $Q$ forman una base para $\mathbb{R}^n $. Además la matriz $Q$ es ortonormal, es decir $QQ^T=Q^TQ=I$.

## Pregunta
¿Qué podemos decir de las filas de la matriz de $Q$ si $A_{n\times m}$ con $n>m$? ¿ De los productos $Q^tQ$ y $QQ^T$?

# Existe alguna aplicación para QR. 

La factorización $QR$ tiene muchas aplicaciones, las más relevantes están en torno que puede ayudar a solucionar adecuadamente problemas de mínimos cuadrados, para introducir este concepto, trabajaremos con la interpolación de un polinomio de grado 7.

Sea los puntos $x_0=2.0$, $x_1=1.2$,...,$x_{10}=4.0$, puntos igualmente espaciados entre el intervalo $[2,4]$ y sea el conjunto $y_i=1+x_i+x_1^2+\cdots+x_i^{10}$ para $0\leq i\leq 10$. Obviamente el polinomio que que une a estos puntos es $P(x)=1+x+x^2+\cdots+x^{10}$. supongamos que no concemos el polinomio $P(x)$, y lo queremos encontrar, de esta forma podemos decir que $$P(x)=c_0+c_1x+\cdots+c_{10}x^{10},$$ de esta forma podemos plantear el sistemas de ecuaciones 

$$\begin{pmatrix}
1&x_0&x_0^2 &  & x^{10}_{0}\\
\vdots&\vdots & \vdots & & \vdots\\
1&x_{10}&x_{10}^2 &  & x^{10}_{10}
\end{pmatrix}\begin{pmatrix}c_0\\\vdots\\c_{10}\end{pmatrix}=\begin{pmatrix}y_0\\\vdots\\y_{10}\end{pmatrix}$$


```{python}
import numpy as np
import scipy.linalg as la

n=11
A = np.zeros([n,n], dtype=np.float64)
c = np.zeros([n,1], dtype=np.float64)
y = np.zeros([n,1], dtype=np.float64)

for j in range(n):
    xi=2.0+0.2*j
    A[j,:]=np.array([xi**i for i in range(n)])
y=np.sum(A,axis=1)    
print(A)
print(y)
```

```{python}
P, L, U = la.lu(A)
b = la.solve_triangular(L , P@y, lower=True)
c = la.solve_triangular(U , b, lower=False)
print(c)
```

```{python}
#Q, R = mgs(A)
Q, R = la.qr(A)
f = la.solve_triangular(R , Q.T@y, lower=False)
print(f)
```

```{python}
b = la.solve_triangular(L , P@y, lower=True)
c = la.solve_triangular(U , b, lower=False)
print(c)

#Q, R = la.qr(A)
#Q, R = cgs(A)
Q, R = mgs(A)

f = la.solve_triangular(R , Q.T@y, lower=False)
print(f)

#np.allclose(A, P @ L@ U)
```
